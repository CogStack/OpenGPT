{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f859a45-5ca7-47cc-8055-dabedd301963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 18:13:35.960625: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-08 18:13:37.052768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, pipeline\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import datasets\n",
    "\n",
    "\n",
    "from opengpt.config import Config\n",
    "from opengpt.model_utils import add_tokens_to_model_and_tokenizer\n",
    "from opengpt.dataset_utils import create_labels, pack_examples\n",
    "from opengpt.data_collator import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd137647-a6d7-49c8-a241-404137ef3b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config(yaml_path='../configs/example_train_config.yaml')\n",
    "model = AutoModelForCausalLM.from_pretrained(config.train.model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.train.model)\n",
    "tokenizer.model_max_length = config.train.max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c389455-d401-4857-a61d-0cc1e72d312b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Added: 5 tokens to the tokenizer\n"
     ]
    }
   ],
   "source": [
    "add_tokens_to_model_and_tokenizer(config, tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0bac3-1504-430f-a28c-0aea4ea28bbc",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6ef4f-3c62-47f8-a717-9d0a57d086ad",
   "metadata": {},
   "source": [
    "The datasets used for training have to have the special tokens as defined in the config. By default this means that the datasets have to be organised as conversations using the `<|user|> <|ai|>` and `<|eos|> <|eod|>` special tokens. An example of a question/answer pair from the NHS-UK dataset:\n",
    "\n",
    "```\n",
    "<|user|> What is high blood pressure? <|eos|> <|ai|> High blood pressure is a condition where the force at which your heart pumps blood around your body is high. It is recorded with 2 numbers, the systolic pressure and the diastolic pressure, both measured in millimetres of mercury (mmHg).\n",
    "References:\n",
    "- https://www.nhs.uk/conditions/Blood-pressure-(high)/Pages/Introduction.aspx <|eos|> <|eod|>\n",
    "```\n",
    "\n",
    "If not done the training scripts below will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a2589a6-2370-4b23-98fc-91ebcf6b24aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling dataset\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.Dataset.from_csv(config.train.datasets)\n",
    "if config.train.shuffle_dataset:\n",
    "    train_dataset = train_dataset.shuffle()\n",
    "    print(\"Shuffling dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab2eea-65d7-4b9e-934a-4179608bd6f4",
   "metadata": {},
   "source": [
    "#### Remove all columns that we do not need, filtering of the dataset can be done before removal if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75b45ea0-c435-4193-aa1b-622a062b4386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove everything but text\n",
    "to_remove = list(train_dataset.column_names)\n",
    "to_remove.remove('text')\n",
    "train_dataset = train_dataset.remove_columns(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e270be31-1643-42c7-8dc1-a9206b88a243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29660 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ignore max_seq_len warning, it is handled by the packer or data_collator\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda examples: tokenizer(examples['text'], add_special_tokens=False), \n",
    "    batched=True, \n",
    "    num_proc=1, \n",
    "    remove_columns=[\"text\"])\n",
    "# Create labels\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda examples: create_labels(examples, config, tokenizer),\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=1,\n",
    ")\n",
    "# We only do packing for the train set\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda examples: pack_examples(examples, config.train.max_seq_len, packing_type=config.train.packing_type),\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6919836a-eab8-43ff-9b1e-2b1d169fe3bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(**config.train.hf_training_arguments.to_dict())\n",
    "dc = DataCollatorWithPadding(tokenizer.pad_token_id, config.train.ignore_index, max_seq_len=config.train.max_seq_len)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=None,\n",
    "    data_collator=dc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4bfc4d5-bbff-4b74-b75f-4ca79ce04124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 8771\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e96d99b-c915-4ac4-8cbe-fb01081a7a42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/zeljko/.venv/llama/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='548' max='548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [548/548 06:27, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.650500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.489700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.445900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.399800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=548, training_loss=1.4748950457050853, metrics={'train_runtime': 388.7346, 'train_samples_per_second': 22.563, 'train_steps_per_second': 1.41, 'total_flos': 1931665648896000.0, 'train_loss': 1.4748950457050853, 'epoch': 1.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a88494-afb1-44a5-b607-6382fe5b0c9c",
   "metadata": {},
   "source": [
    "# Test Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d37cb47-c029-40f5-bc7d-accefae42f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen = pipeline(model=model, tokenizer=tokenizer, task='text-generation', device=model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86ce8f6e-6037-4c2b-8aac-5ad7a129834a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = \"<|user|> What is diabetes? <|eos|> <|ai|>\" # The format with special tokens is required, because of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "daab006f-eda3-43db-b864-a1c1de52d4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50267 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|> What is diabetes? <|eos|> <|ai|> Diabetes is a condition in which the body's insulin levels are too low, which can lead to high blood sugar levels.\n",
      "References:\n",
      "- https://www.nhs.uk/conditions/diabetes/ \n"
     ]
    }
   ],
   "source": [
    "# Temperature is important, and depending on your model different values will be good (this one is for gpt-2)\n",
    "print(gen(t, do_sample=True, max_length=128, temperature=0.2)[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
